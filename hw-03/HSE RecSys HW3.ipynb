{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ №3 Двухуровневый пайплайн\n",
    "#### В этой домашке вам предстоит написать с нуля двустадийную рекомендательную систему. \n",
    "\n",
    "#### Дата выдачи: 10.03.25\n",
    "\n",
    "#### Мягкий дедлайн: 31.03.25 23:59 MSK\n",
    "\n",
    "#### Жесткий дедлайн: 7.04.25 23:59 MSK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание\n",
    "Это творческое задание, в котором вам необходимо реализовать полный цикл построения рекомендательной системы: реализовать кандидат генераторов, придумать и собрать признаки, обучить итоговый ранкер и заинференсить модели на всех пользователей.\n",
    "\n",
    "Вам предоставляется два набора данных: `train.csv` и `test.csv` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T13:59:54.163174Z",
     "start_time": "2025-03-28T13:51:59.027226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'items.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# скачиваем данные\n",
    "# если из этой ячейки не получается, то вот ссылка на папку https://drive.google.com/drive/folders/1HT0Apm8Jft0VPLJtdBBUGu9s1M7vZcoJ?usp=drive_link\n",
    "\n",
    "import gdown\n",
    "# train\n",
    "url = \"https://drive.google.com/uc?id=1-CcS22-UpTJeNcFlA0dVLrEQn8jnI0d-\"\n",
    "\n",
    "output = 'train.csv'\n",
    "gdown.download(url, output, quiet=True)\n",
    "\n",
    "# test\n",
    "url = \"https://drive.google.com/uc?id=11iz3xDh0IIoEIBY0dyRSvByY3qfiT3BG\"\n",
    "\n",
    "output = 'test.csv'\n",
    "gdown.download(url, output, quiet=True)\n",
    "\n",
    "# user features\n",
    "url = \"https://drive.google.com/uc?id=1zl2jWMdUhc-IMakHlihQhJ5PGGZm9-_O\"\n",
    "output = 'users.csv'\n",
    "gdown.download(url, output, quiet=True, fuzzy=True)\n",
    "\n",
    "# item features\n",
    "url = \"https://drive.google.com/uc?id=1chCmpiCKJRjdqNftHc-t2ALl3qbAp2G8\"\n",
    "output = 'items.csv'\n",
    "gdown.download(url, output, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T14:07:00.038163Z",
     "start_time": "2025-04-03T14:06:59.373089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>sex</th>\n",
       "      <th>kids_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>973171</td>\n",
       "      <td>age_25_34</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>М</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>М</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047345</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_40_60</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>age_45_54</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>age_35_44</td>\n",
       "      <td>income_60_90</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840192</th>\n",
       "      <td>339025</td>\n",
       "      <td>age_65_inf</td>\n",
       "      <td>income_0_20</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840193</th>\n",
       "      <td>983617</td>\n",
       "      <td>age_18_24</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840194</th>\n",
       "      <td>251008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840195</th>\n",
       "      <td>590706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840196</th>\n",
       "      <td>166555</td>\n",
       "      <td>age_65_inf</td>\n",
       "      <td>income_20_40</td>\n",
       "      <td>Ж</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840197 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         age        income  sex  kids_flg\n",
       "0        973171   age_25_34  income_60_90    М         1\n",
       "1        962099   age_18_24  income_20_40    М         0\n",
       "2       1047345   age_45_54  income_40_60    Ж         0\n",
       "3        721985   age_45_54  income_20_40    Ж         0\n",
       "4        704055   age_35_44  income_60_90    Ж         0\n",
       "...         ...         ...           ...  ...       ...\n",
       "840192   339025  age_65_inf   income_0_20    Ж         0\n",
       "840193   983617   age_18_24  income_20_40    Ж         1\n",
       "840194   251008         NaN           NaN  NaN         0\n",
       "840195   590706         NaN           NaN    Ж         0\n",
       "840196   166555  age_65_inf  income_20_40    Ж         0\n",
       "\n",
       "[840197 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:11:00.500133Z",
     "start_time": "2025-04-01T14:11:00.075582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15963 entries, 0 to 15962\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   item_id       15963 non-null  int64  \n",
      " 1   content_type  15963 non-null  object \n",
      " 2   title         15963 non-null  object \n",
      " 3   title_orig    11218 non-null  object \n",
      " 4   release_year  15865 non-null  float64\n",
      " 5   genres        15963 non-null  object \n",
      " 6   countries     15926 non-null  object \n",
      " 7   for_kids      566 non-null    float64\n",
      " 8   age_rating    15961 non-null  float64\n",
      " 9   studios       1065 non-null   object \n",
      " 10  directors     14454 non-null  object \n",
      " 11  actors        13344 non-null  object \n",
      " 12  description   15961 non-null  object \n",
      " 13  keywords      15540 non-null  object \n",
      "dtypes: float64(3), int64(1), object(10)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_items = pd.read_csv('items.csv')\n",
    "df_items.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:11:00.675115Z",
     "start_time": "2025-04-01T14:11:00.500738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 608467 entries, 0 to 608466\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   user_id        608467 non-null  int64  \n",
      " 1   item_id        608467 non-null  int64  \n",
      " 2   last_watch_dt  608467 non-null  object \n",
      " 3   total_dur      608467 non-null  int64  \n",
      " 4   watched_pct    608467 non-null  float64\n",
      " 5   target         608467 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:11:02.015202Z",
     "start_time": "2025-04-01T14:11:00.675919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4866956 entries, 0 to 4866955\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   user_id        int64  \n",
      " 1   item_id        int64  \n",
      " 2   last_watch_dt  object \n",
      " 3   total_dur      int64  \n",
      " 4   watched_pct    float64\n",
      " 5   target         int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 222.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:11:02.347606Z",
     "start_time": "2025-04-01T14:11:02.016817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 840197 entries, 0 to 840196\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   user_id   840197 non-null  int64 \n",
      " 1   age       826102 non-null  object\n",
      " 2   income    825421 non-null  object\n",
      " 3   sex       826366 non-null  object\n",
      " 4   kids_flg  840197 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 32.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_users = pd.read_csv('users.csv')\n",
    "df_users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:15:41.033692Z",
     "start_time": "2025-04-01T14:15:40.990330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>last_watch_dt</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>watched_pct</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310745</td>\n",
       "      <td>13373</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>4485</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952323</td>\n",
       "      <td>15997</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>7507</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>889459</td>\n",
       "      <td>11460</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854016</td>\n",
       "      <td>11237</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>5381</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>307257</td>\n",
       "      <td>9132</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>5814</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id last_watch_dt  total_dur  watched_pct  target\n",
       "0   310745    13373    2021-03-13       4485         98.0       1\n",
       "1   952323    15997    2021-03-13       7507        100.0       1\n",
       "2   889459    11460    2021-03-13         60          0.0       0\n",
       "3   854016    11237    2021-03-13       5381         98.0       1\n",
       "4   307257     9132    2021-03-13       5814        100.0       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1 Этап. Модели первого уровня. (max 3 балла)\n",
    "В этом этапе вам необходимо разделить `train` датасет на 2 части: для обучения моделей первого уровня и для их валидации. Единственное условие для разбиения – разбивать нужно по времени. Данные для обучение будем называть `train_stage_1`, данные для валидации `valid_stage_1`. Объемы этих датасетов вы определяет самостоятельно. \n",
    "\n",
    "Для начала нам нужно отобрать кандидатов при помощи легких моделей. Необходимо реализовать 3 типа моделей:\n",
    "1. Любая эвристическая(алгоритмичная) модель на ваш выбор **(0.5 балл)**\n",
    "2. Любая матричная факторизация на ваш выбор **(1 балл)**\n",
    "3. Любая нейросетевая модель на ваш выбор **(1 балла)**\n",
    "\n",
    "Не забудьте использовать скор каждой модели, как признак!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "import scipy.sparse as sp\n",
    "from more_itertools import pairwise\n",
    "from itertools import islice, cycle\n",
    "from implicit.nearest_neighbours import CosineRecommender\n",
    "from implicit.cpu.bpr import BayesianPersonalizedRanking\n",
    "from implicit.cpu.als import AlternatingLeastSquares\n",
    "from implicit.cpu.lmf import LogisticMatrixFactorization\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import threadpoolctl\n",
    "import re\n",
    "from pathlib import Path\n",
    "from rectools.dataset import Dataset\n",
    "\n",
    "from rectools import Columns\n",
    "from rectools.dataset import Dataset\n",
    "from rectools.metrics import (\n",
    "    MAP,\n",
    "    CoveredUsers,\n",
    "    AvgRecPopularity,\n",
    "    Intersection,\n",
    "    HitRate,\n",
    "    Serendipity,\n",
    ")\n",
    "from rectools.models import SASRecModel\n",
    "from rectools.visuals import MetricsApp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T14:38:46.750546Z",
     "start_time": "2025-04-01T14:38:46.072268Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[\"last_watch_dt\"] = pd.to_datetime(df_train[\"last_watch_dt\"])\n",
    "df_test[\"last_watch_dt\"] = pd.to_datetime(df_test[\"last_watch_dt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(\"last_watch_dt\")\n",
    "df_test = df_test.sort_values(\"last_watch_dt\")\n",
    "\n",
    "split_date = df_train[\"last_watch_dt\"].quantile(0.8)\n",
    "train_stage = df_train[df_train[\"last_watch_dt\"] <= split_date].copy()\n",
    "valid_stage = df_train[df_train[\"last_watch_dt\"] > split_date].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-07-26 00:00:00')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stage['last_watch_dt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-07-27 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_stage['last_watch_dt'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(361432, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_stage_cold = valid_stage[~valid_stage['user_id'].isin(train_stage['user_id'].unique())]\n",
    "valid_stage_cold.drop_duplicates(subset=['user_id', 'item_id'], inplace=True)\n",
    "valid_stage_cold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565253, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_stage_hot = valid_stage[valid_stage['user_id'].isin(train_stage['user_id'].unique())]\n",
    "valid_stage_hot.drop_duplicates(subset=['user_id', 'item_id'], inplace=True)\n",
    "valid_stage_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "880421"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_inv_mapping = dict(enumerate(df_train['user_id'].unique()))\n",
    "users_mapping = {v: k for k, v in users_inv_mapping.items()}\n",
    "len(users_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15418"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_inv_mapping = dict(enumerate(df_train['item_id'].unique()))\n",
    "items_mapping = {v: k for k, v in items_inv_mapping.items()}\n",
    "len(items_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coo_matrix(df, user_col='user_id', item_col='item_id', weight_col=None, users_mapping=users_mapping, items_mapping=items_mapping):\n",
    "    weights = np.ones(len(df), dtype=np.float32)\n",
    "    interaction_matrix = sp.coo_matrix((weights, (df[user_col].map(users_mapping.get), df[item_col].map(items_mapping.get))))\n",
    "    return interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 3940271 stored elements and shape (749415, 15009)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_coo_mat = get_coo_matrix(train_stage)\n",
    "train_coo_mat = train_coo_mat.tocsr()\n",
    "train_coo_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"weight\"] = 1\n",
    "df_train[\"datetime\"] = df_train[\"last_watch_dt\"]\n",
    "interactions = df_train[[\"user_id\", \"item_id\", \"datetime\", \"weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = interactions[\"datetime\"].quantile(0.8)\n",
    "train_interactions = interactions[interactions[\"datetime\"] <= split_date].copy()\n",
    "valid_interactions = interactions[interactions[\"datetime\"] > split_date].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall(df_true, df_pred, top_N, rank_col='rank'):\n",
    "    test_recs = df_true.set_index(['user_id', 'item_id']).join(df_pred.set_index(['user_id', 'item_id']))\n",
    "    test_recs = test_recs.sort_values(by=['user_id', rank_col])\n",
    "    test_recs['relevant_items_count'] = test_recs.groupby('user_id')['rank'].transform('size')\n",
    "    users_count = test_recs.index.get_level_values('user_id').nunique()\n",
    "    k = top_N\n",
    "    hit_k = f'hit@{k}'\n",
    "    test_recs[hit_k] = test_recs[rank_col] <= k\n",
    "    recall = (test_recs.groupby('user_id')[hit_k].sum() / test_recs.groupby('user_id')['relevant_items_count'].first()).mean()\n",
    "    return float(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diversity(df_pred, top_N=30, rank_col='rank'):\n",
    "    top_recommendations = df_pred[df_pred[rank_col] <= top_N]\n",
    "    item_counts = top_recommendations['item_id'].value_counts().values\n",
    "    if len(item_counts) == 0:\n",
    "        return 0.0\n",
    "    recommended_counter = item_counts\n",
    "    n_items = len(recommended_counter)\n",
    "    recommended_counter_sorted = np.sort(recommended_counter) \n",
    "    index = np.arange(1, n_items+1) \n",
    "    gini_diversity = 2 * np.sum((n_items + 1 - index)/(n_items+1) * recommended_counter_sorted/np.sum(recommended_counter_sorted))    \n",
    "    return float(gini_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(hot, recs, N=10):\n",
    "    recall_pop = get_recall(valid_stage_hot, recs, 10) \n",
    "    gini_diversity_pop = get_diversity(recs, top_N=10)\n",
    "    print(f\"Индекс Джини {recall_pop:0.2f} и Recall {gini_diversity_pop:0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эврестическая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:45:29.134776Z",
     "start_time": "2025-03-31T14:45:29.126109Z"
    }
   },
   "outputs": [],
   "source": [
    "class HeuristicModel:\n",
    "    def __init__(self, max_K=200, days=30, item_column='item_id', dt_column='date'):\n",
    "        self.max_K = max_K\n",
    "        self.days = days\n",
    "        self.item_column = item_column\n",
    "        self.dt_column = dt_column\n",
    "        self.recommendations = []\n",
    "        \n",
    "    def fit(self, df, ):\n",
    "        min_date = df[self.dt_column].max().normalize() - pd.DateOffset(days=self.days)\n",
    "        self.recommendations = df.loc[df[self.dt_column] > min_date, self.item_column].value_counts().head(self.max_K).index.values\n",
    "    \n",
    "    def recommend(self, users=None, N=10):\n",
    "        recs = self.recommendations[:N]\n",
    "        if users is None:\n",
    "            return recs\n",
    "        else:\n",
    "            return list(islice(cycle([recs]), len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15297,  9728, 10440,  3734, 13865,  2657,  4151, 12192,  4495,\n",
       "        4880])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_model = HeuristicModel(days=30, dt_column='last_watch_dt')\n",
    "pop_model.fit(train_stage)\n",
    "\n",
    "top10_recs = pop_model.recommend(N=10)\n",
    "top10_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310745</td>\n",
       "      <td>15297</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310745</td>\n",
       "      <td>9728</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310745</td>\n",
       "      <td>10440</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310745</td>\n",
       "      <td>3734</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310745</td>\n",
       "      <td>13865</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749414</th>\n",
       "      <td>778309</td>\n",
       "      <td>2657</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749414</th>\n",
       "      <td>778309</td>\n",
       "      <td>4151</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749414</th>\n",
       "      <td>778309</td>\n",
       "      <td>12192</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749414</th>\n",
       "      <td>778309</td>\n",
       "      <td>4495</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749414</th>\n",
       "      <td>778309</td>\n",
       "      <td>4880</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7494150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id item_id  rank\n",
       "0        310745   15297     1\n",
       "0        310745    9728     2\n",
       "0        310745   10440     3\n",
       "0        310745    3734     4\n",
       "0        310745   13865     5\n",
       "...         ...     ...   ...\n",
       "749414   778309    2657     6\n",
       "749414   778309    4151     7\n",
       "749414   778309   12192     8\n",
       "749414   778309    4495     9\n",
       "749414   778309    4880    10\n",
       "\n",
       "[7494150 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_pop = pd.DataFrame({'user_id': train_stage['user_id'].unique()})\n",
    "recs_pop['item_id'] = pop_model.recommend(recs_pop['user_id'], N=10)\n",
    "recs_pop = recs_pop.explode('item_id')\n",
    "recs_pop['rank'] = recs_pop.groupby('user_id').cumcount() + 1\n",
    "recs_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс Джини 0.20 и Recall 1.00\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(valid_stage_hot, recs_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Матричная Факторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad2ba5a58884920b2d65aee903bc004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_model = AlternatingLeastSquares()\n",
    "als_model.fit(train_coo_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recs(model, train_matrix, user_mapping, item_inv_mapping, N=10):\n",
    "    recommendations = {}\n",
    "    for user in user_mapping.keys():\n",
    "        user_id = user_mapping[user]\n",
    "        try:\n",
    "            ids, scores = model.recommend(\n",
    "                user_id,\n",
    "                train_matrix[user_id],\n",
    "                N=N,\n",
    "                filter_already_liked_items=True\n",
    "            )\n",
    "            recs = [(item_inv_mapping[item], score) for item, score in zip(ids, scores)]\n",
    "            recommendations[user] = recs\n",
    "        except Exception:\n",
    "            print(\"Out of range\")\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_als = generate_recs(als_model, train_coo_mat, users_mapping, items_inv_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491856</td>\n",
       "      <td>(7713, 0.018015875)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491856</td>\n",
       "      <td>(10436, 0.01408476)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491856</td>\n",
       "      <td>(12132, 0.013723382)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491856</td>\n",
       "      <td>(6945, 0.012837407)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>491856</td>\n",
       "      <td>(6939, 0.01059416)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151387</th>\n",
       "      <td>509102</td>\n",
       "      <td>(5693, 0.013842618)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151387</th>\n",
       "      <td>509102</td>\n",
       "      <td>(1287, 0.012484793)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151387</th>\n",
       "      <td>509102</td>\n",
       "      <td>(3402, 0.012346473)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151387</th>\n",
       "      <td>509102</td>\n",
       "      <td>(16361, 0.01221867)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151387</th>\n",
       "      <td>509102</td>\n",
       "      <td>(13935, 0.011896464)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1513880 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id               item_id  rank\n",
       "0        491856   (7713, 0.018015875)     1\n",
       "0        491856   (10436, 0.01408476)     2\n",
       "0        491856  (12132, 0.013723382)     3\n",
       "0        491856   (6945, 0.012837407)     4\n",
       "0        491856    (6939, 0.01059416)     5\n",
       "...         ...                   ...   ...\n",
       "151387   509102   (5693, 0.013842618)     6\n",
       "151387   509102   (1287, 0.012484793)     7\n",
       "151387   509102   (3402, 0.012346473)     8\n",
       "151387   509102   (16361, 0.01221867)     9\n",
       "151387   509102  (13935, 0.011896464)    10\n",
       "\n",
       "[1513880 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_als = pd.DataFrame({'user_id': valid_stage_hot['user_id'].unique()})\n",
    "recs_als['item_id'] = recs_als['user_id'].map(mapper_als)\n",
    "recs_als = recs_als.explode('item_id')\n",
    "recs_als['rank'] = recs_als.groupby('user_id').cumcount() + 1\n",
    "recs_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс Джини 0.00 и Recall 0.93\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(valid_stage_hot, recs_als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нейросетевая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.construct(\n",
    "    interactions_df=train_interactions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: rectools[torch]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Requirement `torch` is not satisfied. Run `pip install rectools[torch]` to install extra requirements before accessing SASRecModel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sasrec \u001b[38;5;241m=\u001b[39m SASRecModel(\n\u001b[1;32m      2\u001b[0m     session_max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      3\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     n_factors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      5\u001b[0m     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      6\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m      7\u001b[0m     deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/HSE/lib/python3.11/site-packages/rectools/compat.py:25\u001b[0m, in \u001b[0;36mRequirementUnavailable.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs: tp\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: tp\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tp\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Raise ImportError when an attempt to instantiate an unavailable model is made\"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequirement `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` is not satisfied. Run `pip install rectools[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mrequirement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto install extra requirements before accessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Requirement `torch` is not satisfied. Run `pip install rectools[torch]` to install extra requirements before accessing SASRecModel."
     ]
    }
   ],
   "source": [
    "sasrec = SASRecModel(\n",
    "    session_max_len=20,\n",
    "    loss=\"softmax\",\n",
    "    n_factors=64,\n",
    "    lr=0.001,\n",
    "    batch_size=16,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:45:41.092752Z",
     "start_time": "2025-03-31T14:45:39.959986Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=50):\n",
    "        super(NeuralNetworkModel, self).__init__()\n",
    "        self.user_embeddings = nn.Embedding(n_users, n_factors)\n",
    "        self.item_embeddings = nn.Embedding(n_items, n_factors)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_factors * 2, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        user_vector = self.user_embeddings(user_id)\n",
    "        item_vector = self.item_embeddings(item_id)\n",
    "        concat = torch.cat([user_vector, item_vector], dim=1)\n",
    "        return self.fc(concat)\n",
    "\n",
    "class RecommendationNeuralNetwork:\n",
    "    def __init__(self, train_data, n_factors=50, n_epochs=10, batch_size=64, learning_rate=0.001):\n",
    "        n_users = train_data['user_id'].max() + 1\n",
    "        n_items = train_data['item_id'].max() + 1\n",
    "\n",
    "        self.model = NeuralNetworkModel(n_users, n_items, n_factors)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.user_tensor = torch.tensor(train_data['user_id'].values, dtype=torch.long)\n",
    "        self.item_tensor = torch.tensor(train_data['item_id'].values, dtype=torch.long)\n",
    "        self.target_tensor = torch.tensor(train_data['target'].values, dtype=torch.float)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            permutation = torch.randperm(self.user_tensor.size(0))\n",
    "\n",
    "            for i in range(0, self.user_tensor.size(0), self.batch_size):\n",
    "                indices = permutation[i:i + self.batch_size]\n",
    "                user_batch = self.user_tensor[indices]\n",
    "                item_batch = self.item_tensor[indices]\n",
    "                target_batch = self.target_tensor[indices]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                predictions = self.model(user_batch, item_batch).squeeze()\n",
    "                loss = self.criterion(predictions, target_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{self.n_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    def predict_score(self, user_id, item_id):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            user_tensor = torch.tensor([user_id], dtype=torch.long)\n",
    "            item_tensor = torch.tensor([item_id], dtype=torch.long)\n",
    "            return self.model(user_tensor, item_tensor).item()\n",
    "\n",
    "    def recommend_top_k(self, user_id, k=10):\n",
    "        self.model.eval()\n",
    "        item_ids = np.arange(self.model.item_embeddings.num_embeddings)\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids), dtype=torch.long)\n",
    "        item_tensor = torch.tensor(item_ids, dtype=torch.long)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            scores = self.model(user_tensor, item_tensor).numpy()\n",
    "        \n",
    "        top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "        return item_ids[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T14:45:43.126465Z",
     "start_time": "2025-03-31T14:45:43.063133Z"
    }
   },
   "outputs": [],
   "source": [
    "my_heuristic_model = HeuristicModel(train_stage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-31T14:47:49.751498Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_matrix_factorization = SVDModel(train_stage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_neural_network = RecommendationNeuralNetwork(train_stage_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая модель должна уметь:\n",
    "1) для пары user_item предсказывать скор релевантности (масштаб скора не важен), важно обработать случаи, когда модель не можеn проскорить пользователя или айтем, вместо этого вернуть какое-то дефолтное значение\n",
    "2) для всех пользователей вернуть top-k самых релевантных айтемов (тут вам скоры не нужны)\n",
    "\n",
    "\n",
    "Дополнительно можно провести анализ кандидат генератов, измерить насколько различные айтемы они рекомендуют, например с помощью таких метрик как: [Ranked based overlap](https://github.com/changyaochen/rbo) или различные вариации [Diversity](https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation/blob/master/Base/Evaluation/metrics.py#L289). **(1 балл)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2 Этап. Генерация и сборка признаков. (max 2 балла)\n",
    "Необходимо собрать минимум 10 осмысленных (`np.radndom.rand()` не подойдет) признаков, при этом:\n",
    "1. 2 должны относиться только к сущности \"пользователь\" (например средний % просмотра фильмов у этой возрастной категории)\n",
    "2. 2 должны относиться только к сущности \"айтем\" (например средний средний % просмотра данного фильма)\n",
    "3. 6 признаков, которые показывают связь пользователя и айтема (например средний % просмотра фильмов с данным актером (айтем) у пользователей с таким же полом (пользователь)). \n",
    "\n",
    "### ВАЖНО!  \n",
    "\n",
    "1. **В датасете есть колонка `watched_prct`. Ее можно использовать для генерации признаков (например сколько пользователь в среднем смотрит фильмы), но нельзя подавать в модель, как отдельную фичу, потому что она напрямую связана с target.**\n",
    "2. **Все признаки должны быть собраны без дата лика, то есть если пользователь посмотрел фильм 10 августа, то признаки мы можем считать только на данных до 9 августа включительно.**\n",
    "\n",
    "\n",
    "### Разбалловка\n",
    "Обучение ранкера будет проходить на `valid_stage_1`, как  раз на которой мы валидировали модели, а тестировать на `test`. Поэтому есть 2 варианта сборки признаков, **реализовать нужно только 1 из них:**\n",
    "1. Для обучения собираем признаки на первый день `valid_stage_1`, а для теста на первый день `test`. Например, если `valid_stage_1` начинается 5 сентября, то все признаки мы можем собирать только по 4 сентября включительно. **(1 балл)**\n",
    "2. Признаки будем собирать честно на каждый день, то есть на 5 сентября собираем с начала до 4, на 6 сентября с начала до 5 и т.д. **(2 балла)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_with_features = # YOUR CODE IS HERE\n",
    "test_df_with_features = # YOUR CODE IS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3 Этап. Обучение финального ранкера (max 2 балла)\n",
    "Собрав все признаки из этапа 2, добавив скоры моделей из этапа 1 для каждой пары пользователь-айтем (где это возможно), пришло время обучать ранкер. В качестве ранкера можно использовать либо [xgboost](https://xgboost.readthedocs.io/en/stable/) или [catboost](https://catboost.ai/). Обучать можно как `Classfier`, так и `Ranker`, выбираем то, что лучше сработает. Обучение ранкера будет проходить на `valid_stage_1`, как  раз на которой мы валидировали модели, а тестировать на `test`, которую мы до сих пор не трогали.  Заметьте, что у нас в тесте есть холодные пользователи – те, кого не было в train и активные – те, кто был в train. Возможно их стоит обработать по отдельности (а может и нет).  \n",
    "(1 балл)\n",
    "\n",
    "После получения лучшей модели надо посмотреть на важность признаков и [shap values](https://shap.readthedocs.io/en/latest/index.html), чтобы:\n",
    "1. Интерпритировать признаки, которые вы собрали, насколько они полезные\n",
    "2. Проверить наличие ликов – если важность фичи в 100 раз больше, чем у всех остальных, то явно что-то не то  \n",
    "\n",
    "(1 балл)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR FIT PREDICT CODE HERE\n",
    "model.fit()\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4 Этап. Инференс лучшего ранкера (max 3 балла)\n",
    "\n",
    "Теперь мы хотим построить рекомендации \"на завтра\", для этого нам нужно:\n",
    "\n",
    "1. Обучить модели первого уровня на всех (train+test) данных (0.5 балла)\n",
    "2. Для каждой модели первого уровня для каждого пользователя сгененировать N кандидатов (0.5 балла)\n",
    "3. \"Склеить\" всех кандидатов для каждого пользователя (дубли выкинуть), посчитать скоры от всех моделей (0.5 балла)\n",
    "4. Собрать фичи для ваших кандидатов (теперь можем считать признаки на всех данных) (0.5 балла)\n",
    "5. Проскорить всех кандидатов бустингом и оставить k лучших (0.5 балла)\n",
    "6. Посчитать разнообразие(Diversity) и построить график от Diversity(k) (0.5 балла)\n",
    "\n",
    "\n",
    "Все гиперпараметры (N, k) определяете только Вы!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8807970779778823"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "1 / (1 + math.exp(-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "25ec213ceadb4c12ac11976b0ba5e57c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b78d96f7d1bb451abbc9d717d20a558a",
       "style": "IPY_MODEL_8286a1b03ca249e7a4c266ed84bf9149",
       "value": " 15/15 [01:26&lt;00:00,  5.78s/it]"
      }
     },
     "53bd1d41a34b4c06bc3c0cff365aef78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5d51c303387241a78aae3e63897b41b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6c2793fa8f9247b9ad140474ed713ede": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_53bd1d41a34b4c06bc3c0cff365aef78",
       "max": 15,
       "style": "IPY_MODEL_763b65dddf5d4c4fa2100978b4865bc4",
       "value": 15
      }
     },
     "763b65dddf5d4c4fa2100978b4865bc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8286a1b03ca249e7a4c266ed84bf9149": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "98bb77548c044db4a0d212da6c89cbf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b78d96f7d1bb451abbc9d717d20a558a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bad2ba5a58884920b2d65aee903bc004": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c6d5d4eeda6a42e0829700d4929bf3d7",
        "IPY_MODEL_6c2793fa8f9247b9ad140474ed713ede",
        "IPY_MODEL_25ec213ceadb4c12ac11976b0ba5e57c"
       ],
       "layout": "IPY_MODEL_5d51c303387241a78aae3e63897b41b5"
      }
     },
     "c6d5d4eeda6a42e0829700d4929bf3d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_98bb77548c044db4a0d212da6c89cbf5",
       "style": "IPY_MODEL_f10c7e8c2e79470db1565f55a6f4af5d",
       "value": "100%"
      }
     },
     "f10c7e8c2e79470db1565f55a6f4af5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
